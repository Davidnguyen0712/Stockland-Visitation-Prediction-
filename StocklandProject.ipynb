{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stockland Project \n",
    "\n",
    "Visitation Predition based on weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data set \n",
    "### 1, Stockland Visitation dataset: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset               8190\n",
       "Date                8190\n",
       "Count visitation    7050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"data/Stockland - Visitation Data.csv\", encoding=None )\n",
    "df_1.head()\n",
    "df_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, Weather dataset (collected from BOM.gov.au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset              8190\n",
       "Date               8190\n",
       "Min temperature    8068\n",
       "Max temperature    8126\n",
       "Solar exposure     8186\n",
       "Rainfall           7886\n",
       "Raining period     5597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv(\"data/weather.csv\", encoding=None)\n",
    "df_2.head()\n",
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset</th>\n",
       "      <th>Date</th>\n",
       "      <th>Count visitation</th>\n",
       "      <th>Min temperature</th>\n",
       "      <th>Max temperature</th>\n",
       "      <th>Solar exposure</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Raining period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>1/01/2021</td>\n",
       "      <td>11878.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>2/01/2021</td>\n",
       "      <td>7962.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>3/01/2021</td>\n",
       "      <td>12918.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>4/01/2021</td>\n",
       "      <td>12796.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>32.7</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baldivis</td>\n",
       "      <td>5/01/2021</td>\n",
       "      <td>13321.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>34.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Asset       Date  Count visitation  Min temperature  Max temperature  \\\n",
       "0  Baldivis  1/01/2021           11878.0             19.9             30.0   \n",
       "1  Baldivis  2/01/2021            7962.0             19.5             32.6   \n",
       "2  Baldivis  3/01/2021           12918.0             18.0             32.0   \n",
       "3  Baldivis  4/01/2021           12796.0             17.3             32.7   \n",
       "4  Baldivis  5/01/2021           13321.0             18.2             34.2   \n",
       "\n",
       "   Solar exposure  Rainfall   Raining period  \n",
       "0            30.7        0.0             NaN  \n",
       "1            30.2        0.0             NaN  \n",
       "2            24.3        0.0             NaN  \n",
       "3            30.9        0.0             NaN  \n",
       "4            30.8        0.0             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.merge(df_1, df_2, on = ['Asset','Date'], how = \"inner\")\n",
    "df_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[\"Solar exposure\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset               8190\n",
       "Date                8190\n",
       "Count visitation    7050\n",
       "Min temperature     8068\n",
       "Max temperature     8126\n",
       "Solar exposure      8186\n",
       "Rainfall            7886\n",
       "Raining period      5597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "### Filling missing values\n",
    "\n",
    "( detailed explanation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asset                  0\n",
       "Date                   0\n",
       "Count visitation    1140\n",
       "Min temperature      122\n",
       "Max temperature       64\n",
       "Solar exposure         4\n",
       "Rainfall             304\n",
       "Raining period      2593\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check na and missing values\n",
    "df_full.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impure missing data for rainfall adn rain period: \n",
    "For rainfall, if there is a missing data, we assume that the rainfall is 0 (no rain). \n",
    "By looking at the raining period columns in the dataset collected from BOM, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Rainfall ']=df_full['Rainfall '].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use backwards fill for raining period \n",
    "df_full['Raining period']= df_full['Raining period'].bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_full)):\n",
    "    if df_full['Rainfall '].loc[i]==0:\n",
    "        df_full['Raining period'].loc[i]=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use forward fill to impute missing values of min temperature, max temperature and solar exposure\n",
    "df_full['Max temperature']=df_full['Max temperature'].ffill()\n",
    "df_full['Min temperature']=df_full['Min temperature'].ffill()\n",
    "df_full['Solar exposure']=df_full['Solar exposure'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummies variable for Assets and month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.get_dummies(df_full,columns=['Asset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract month variable\n",
    "from datetime import datetime \n",
    "for i in range(len(df_full)):   \n",
    "    df_full['Date'].loc[i]= datetime.strptime(df_full['Date'].loc[i],'%d/%m/%Y')\n",
    "\n",
    "\n",
    "df_full['Date'].loc[1].month\n",
    "df_full['Month']= \"\"\n",
    "for i in range(len(df_full)):\n",
    "    df_full['Month'].loc[i]=df_full['Date'].loc[i].month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into categorical month\n",
    "\n",
    "df_full['Month']= df_full['Month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.get_dummies(df_full,columns=['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                       0\n",
       "Count visitation        1140\n",
       "Min temperature            0\n",
       "Max temperature            0\n",
       "Solar exposure             0\n",
       "Rainfall                   0\n",
       "Raining period             0\n",
       "Asset_Baldivis             0\n",
       "Asset_Balgowlah            0\n",
       "Asset_Birtinya             0\n",
       "Asset_Bull Creek           0\n",
       "Asset_Burleigh             0\n",
       "Asset_Gladstone            0\n",
       "Asset_Glendale             0\n",
       "Asset_Green Hills          0\n",
       "Asset_Harrisdale           0\n",
       "Asset_Hervey Bay           0\n",
       "Asset_Merrylands           0\n",
       "Asset_Riverton             0\n",
       "Asset_Rockhampton          0\n",
       "Asset_Wendouree            0\n",
       "Asset_Wetherill Park       0\n",
       "Month_1                    0\n",
       "Month_10                   0\n",
       "Month_11                   0\n",
       "Month_12                   0\n",
       "Month_2                    0\n",
       "Month_3                    0\n",
       "Month_4                    0\n",
       "Month_5                    0\n",
       "Month_6                    0\n",
       "Month_7                    0\n",
       "Month_8                    0\n",
       "Month_9                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_full[df_full['Count visitation'].notna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    7050\n",
       "Count visitation        7050\n",
       "Min temperature         7050\n",
       "Max temperature         7050\n",
       "Solar exposure          7050\n",
       "Rainfall                7050\n",
       "Raining period          7050\n",
       "Asset_Baldivis          7050\n",
       "Asset_Balgowlah         7050\n",
       "Asset_Birtinya          7050\n",
       "Asset_Bull Creek        7050\n",
       "Asset_Burleigh          7050\n",
       "Asset_Gladstone         7050\n",
       "Asset_Glendale          7050\n",
       "Asset_Green Hills       7050\n",
       "Asset_Harrisdale        7050\n",
       "Asset_Hervey Bay        7050\n",
       "Asset_Merrylands        7050\n",
       "Asset_Riverton          7050\n",
       "Asset_Rockhampton       7050\n",
       "Asset_Wendouree         7050\n",
       "Asset_Wetherill Park    7050\n",
       "Month_1                 7050\n",
       "Month_10                7050\n",
       "Month_11                7050\n",
       "Month_12                7050\n",
       "Month_2                 7050\n",
       "Month_3                 7050\n",
       "Month_4                 7050\n",
       "Month_5                 7050\n",
       "Month_6                 7050\n",
       "Month_7                 7050\n",
       "Month_8                 7050\n",
       "Month_9                 7050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Count visitation', 'Min temperature', 'Max temperature',\n",
       "       'Solar exposure', 'Rainfall ', 'Raining period', 'Asset_Baldivis',\n",
       "       'Asset_Balgowlah', 'Asset_Birtinya', 'Asset_Bull Creek',\n",
       "       'Asset_Burleigh', 'Asset_Gladstone', 'Asset_Glendale',\n",
       "       'Asset_Green Hills', 'Asset_Harrisdale', 'Asset_Hervey Bay',\n",
       "       'Asset_Merrylands', 'Asset_Riverton', 'Asset_Rockhampton',\n",
       "       'Asset_Wendouree', 'Asset_Wetherill Park', 'Month_1', 'Month_10',\n",
       "       'Month_11', 'Month_12', 'Month_2', 'Month_3', 'Month_4', 'Month_5',\n",
       "       'Month_6', 'Month_7', 'Month_8', 'Month_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_clean =shuffle(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiiting models \n",
    "### Linear regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-94ebb19b71b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(sc.mean_, sc.scale_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'means:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sigmas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "y_train = df_clean['Count visitation']\n",
    "X_train = df_clean.drop(columns = ['Count visitation', 'Date'])\n",
    "\n",
    "#sc = StandardScaler()\n",
    "\n",
    "#sc.fit(X_train)\n",
    "\n",
    "# print(dir(sc))\n",
    "# print(sc.mean_, sc.scale_)\n",
    "\n",
    "print('means:', X_train.mean(axis=0), X_train_scaled.mean(axis=0))\n",
    "print('sigmas', X_train.std(axis=0), X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores\n",
      " [[-5.42272894e+19]\n",
      " [ 3.47430929e-01]\n",
      " [-4.27449463e+20]\n",
      " [-1.75062121e-01]\n",
      " [-2.31926676e+20]\n",
      " [ 8.40371199e-01]\n",
      " [-6.19294216e+20]\n",
      " [ 5.50454821e-01]\n",
      " [-5.64572802e+20]\n",
      " [-5.88766818e-01]]\n",
      "CV accuracy: -189747044566345121792.000 +/- 241178769772818759680.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "scores_lr = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "# print(scores_v2)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 130427.133\n",
      "R^2 train: 0.998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=30)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores\n",
      " [[0.64605473]\n",
      " [0.59057213]\n",
      " [0.64914497]\n",
      " [0.67950281]\n",
      " [0.64571156]\n",
      " [0.57371892]\n",
      " [0.7077282 ]\n",
      " [0.56660276]\n",
      " [0.61669283]\n",
      " [0.63819033]]\n",
      "CV accuracy: 0.631 +/- 0.043\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(estimator=tree, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "# print(scores_v2)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 1522586.243\n",
      "R^2 train: 0.971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = forest.predict(X_train)\n",
    "\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores\n",
      " [[0.81558455]\n",
      " [0.77405033]\n",
      " [0.77795415]\n",
      " [0.78625463]\n",
      " [0.7257761 ]\n",
      " [0.80183222]\n",
      " [0.77949239]\n",
      " [0.7982009 ]\n",
      " [0.83047601]\n",
      " [0.8095366 ]]\n",
      "CV accuracy: 0.790 +/- 0.027\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(estimator=forest, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "# print(scores_v2)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning for selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150, 200, 250], 'max_features': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_features': 11, 'max_depth': 20, 'bootstrap': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in range(50,300,50)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in range(4,22)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "              'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=1, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "# Ouput the best params\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 2672874.501\n",
      "R^2 train: 0.950\n"
     ]
    }
   ],
   "source": [
    "# final = RandomForestRegressor(n_estimators= 200, max_features= 7, max_depth= 30, bootstrap= False)\n",
    "# final.fit(X_train, y_train)\n",
    "\n",
    "final = RandomForestRegressor(n_estimators= 250, max_features= 11, max_depth= 20, bootstrap= True)\n",
    "final.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = final.predict(X_train)\n",
    "\n",
    "\n",
    "print(f'MSE train: {mean_squared_error(y_train, y_train_pred):.3f}')\n",
    "print(f'R^2 train: {r2_score(y_train, y_train_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores\n",
      " [[0.8259003 ]\n",
      " [0.78306467]\n",
      " [0.79693074]\n",
      " [0.80520329]\n",
      " [0.75252035]\n",
      " [0.81294595]\n",
      " [0.79097298]\n",
      " [0.80060965]\n",
      " [0.84379298]\n",
      " [0.82186072]]\n",
      "CV accuracy: 0.803 +/- 0.024\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(estimator=final, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "# print(scores_v2)\n",
    "\n",
    "print(f'CV accuracy scores\\n {scores_lr.reshape(-1,1)}')\n",
    "print(f'CV accuracy: {np.mean(scores_lr):.3f} +/- {np.std(scores_lr):.3f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
